{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61ca6ff6-b6c9-4f88-8f2e-fc069aeef5f7",
   "metadata": {},
   "source": [
    "# Modelizacion del conjunto de datos\n",
    "\n",
    "En este fichero Jupyter, procederemos a construir, entrenar y validar un modelo de Deep Learning con el que trataremos de modelizar el conjunto de datos que se ha trabajado en el fichero anterior.\n",
    "\n",
    "En el fichero anterior nos ocupamos de procesar el dataset a utilizar, y guardar una copia de este, ya modificado, por lo que unicamente deberemos de dividir el dataset antes de la construccion del modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ebdec2-ef0e-46fb-a4eb-c82d96dc2bf8",
   "metadata": {},
   "source": [
    "# Importar las librerías necesarias\n",
    "\n",
    "La siguiente celda reuna las importaciones de todas las librerías, clases y métodos que se utilizan en este Jupyter Notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7942493-957f-4383-8f65-c990a736dbff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librerías de análisis y manipulación de datos\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Clases y metodos para el desarrollo del modelo\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential, layers\n",
    "from sklearn.metrics import confusion_matrix, classification_report, f1_score, precision_score, recall_score, accuracy_score\n",
    "\n",
    "\n",
    "# Librerías de visualización de datos\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Otros\n",
    "import os\n",
    "import json\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(action = \"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d4727b4-80e6-4f56-9e4c-8a5c261e214f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d59940c-706c-461d-85ac-bafbd069628c",
   "metadata": {},
   "source": [
    "# Cargando el conjunto de datos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "715a8b43-1922-4252-97b7-4f54f062ef43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>cap-diameter</th>\n",
       "      <th>stem-height</th>\n",
       "      <th>stem-width</th>\n",
       "      <th>cap-shape_o</th>\n",
       "      <th>cap-shape_p</th>\n",
       "      <th>cap-shape_s</th>\n",
       "      <th>cap-shape_b</th>\n",
       "      <th>cap-shape_c</th>\n",
       "      <th>cap-shape_x</th>\n",
       "      <th>...</th>\n",
       "      <th>season_u</th>\n",
       "      <th>season_w</th>\n",
       "      <th>ring-type_p</th>\n",
       "      <th>ring-type_l</th>\n",
       "      <th>ring-type_r</th>\n",
       "      <th>ring-type_g</th>\n",
       "      <th>ring-type_m</th>\n",
       "      <th>ring-type_e</th>\n",
       "      <th>ring-type_f</th>\n",
       "      <th>ring-type_z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.240155</td>\n",
       "      <td>0.499705</td>\n",
       "      <td>0.164469</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.261782</td>\n",
       "      <td>0.530366</td>\n",
       "      <td>0.175055</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.220949</td>\n",
       "      <td>0.524764</td>\n",
       "      <td>0.170725</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.222563</td>\n",
       "      <td>0.464917</td>\n",
       "      <td>0.153787</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.230148</td>\n",
       "      <td>0.487323</td>\n",
       "      <td>0.165528</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0.241446</td>\n",
       "      <td>0.525943</td>\n",
       "      <td>0.180830</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>0.233538</td>\n",
       "      <td>0.522111</td>\n",
       "      <td>0.162545</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>0.233699</td>\n",
       "      <td>0.502064</td>\n",
       "      <td>0.167838</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>0.201259</td>\n",
       "      <td>0.509139</td>\n",
       "      <td>0.179867</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>0.212556</td>\n",
       "      <td>0.472877</td>\n",
       "      <td>0.162448</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 72 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   class  cap-diameter  stem-height  stem-width  cap-shape_o  cap-shape_p  \\\n",
       "0      1      0.240155     0.499705    0.164469            0            0   \n",
       "1      1      0.261782     0.530366    0.175055            0            0   \n",
       "2      1      0.220949     0.524764    0.170725            0            0   \n",
       "3      1      0.222563     0.464917    0.153787            0            0   \n",
       "4      1      0.230148     0.487323    0.165528            0            0   \n",
       "5      1      0.241446     0.525943    0.180830            0            0   \n",
       "6      1      0.233538     0.522111    0.162545            0            0   \n",
       "7      1      0.233699     0.502064    0.167838            0            0   \n",
       "8      1      0.201259     0.509139    0.179867            0            0   \n",
       "9      1      0.212556     0.472877    0.162448            0            0   \n",
       "\n",
       "   cap-shape_s  cap-shape_b  cap-shape_c  cap-shape_x  ...  season_u  \\\n",
       "0            0            0            0            1  ...         0   \n",
       "1            0            0            0            1  ...         1   \n",
       "2            0            0            0            1  ...         0   \n",
       "3            0            0            0            0  ...         0   \n",
       "4            0            0            0            1  ...         0   \n",
       "5            0            0            0            1  ...         1   \n",
       "6            0            0            0            0  ...         0   \n",
       "7            0            0            0            1  ...         1   \n",
       "8            0            0            0            0  ...         0   \n",
       "9            0            0            0            0  ...         0   \n",
       "\n",
       "   season_w  ring-type_p  ring-type_l  ring-type_r  ring-type_g  ring-type_m  \\\n",
       "0         1            0            0            0            1            0   \n",
       "1         0            0            0            0            1            0   \n",
       "2         1            0            0            0            1            0   \n",
       "3         1            1            0            0            0            0   \n",
       "4         1            1            0            0            0            0   \n",
       "5         0            1            0            0            0            0   \n",
       "6         1            0            0            0            1            0   \n",
       "7         0            1            0            0            0            0   \n",
       "8         0            1            0            0            0            0   \n",
       "9         1            1            0            0            0            0   \n",
       "\n",
       "   ring-type_e  ring-type_f  ring-type_z  \n",
       "0            0            0            0  \n",
       "1            0            0            0  \n",
       "2            0            0            0  \n",
       "3            0            0            0  \n",
       "4            0            0            0  \n",
       "5            0            0            0  \n",
       "6            0            0            0  \n",
       "7            0            0            0  \n",
       "8            0            0            0  \n",
       "9            0            0            0  \n",
       "\n",
       "[10 rows x 72 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Cargo el conjunto de datos del fichero \"secondary_data.csv\" en memoria\n",
    "\n",
    "# Ruta del fichero \"primary_data.csv\"\n",
    "secondary_data_processed_path = \"../data/processed/secondary_data_processed.csv\"\n",
    "\n",
    "# Defino un objeto DataFrame que cargue en memoria el fichero .csv\n",
    "processed_data_df = pd.read_csv(secondary_data_processed_path, low_memory = False)\n",
    "\n",
    "# 10 primeros registros del DataFrame\n",
    "processed_data_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580b7b79-eb1f-41b5-9957-11b6ccc05a7b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ade2a09-8dff-41ed-a805-a44e3d640928",
   "metadata": {},
   "source": [
    "## Division del conjunto de datos\n",
    "\n",
    "Para el desarrollo del modelo, divido el dataset completo en dos dos subconjuntos, de entrenamiento y testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "da929d37-0c3f-4a8e-8496-70f7dcfc363d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = processed_data_df.drop(columns = ['class'])\n",
    "y = processed_data_df['class']\n",
    "\n",
    "# Convierto las matrices de caracteristicas y vector de salida en arrays de Numpy\n",
    "X = np.array(X, dtype = \"float16\")\n",
    "y = np.array(y, dtype = \"float16\").reshape(-1, 1)\n",
    "\n",
    "# Genero los subconjuntos de datos\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "40db9cea-75ad-43dd-8c5e-8a29d81d2eda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46878, 71)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0c5c3967-9feb-46c3-a5bf-d7706b3ba770",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11720, 71)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5f17dbe1-9518-419f-9fe6-d2d3de6f6e6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46878, 1)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "28457ba7-9068-4aa9-9eb4-823e22d70c3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11720, 1)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "01cc60b5-fa94-4ead-bd4a-65490cc36a42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.05908, 0.1338 , 0.05984, ..., 0.     , 0.     , 1.     ],\n",
       "       [0.03293, 0.0796 , 0.0489 , ..., 0.     , 1.     , 0.     ],\n",
       "       [0.3113 , 0.277  , 0.2483 , ..., 0.     , 1.     , 0.     ],\n",
       "       ...,\n",
       "       [0.192  , 0.318  , 0.128  , ..., 0.     , 0.     , 0.     ],\n",
       "       [0.076  , 0.1459 , 0.0797 , ..., 0.     , 1.     , 0.     ],\n",
       "       [0.3625 , 0.1692 , 0.3247 , ..., 0.     , 1.     , 0.     ]],\n",
       "      dtype=float16)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "31f6ad33-0186-4857-8612-1a4c1717e4d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.05908, 0.1338 , 0.05984, ..., 0.     , 0.     , 1.     ],\n",
       "       [0.03293, 0.0796 , 0.0489 , ..., 0.     , 1.     , 0.     ],\n",
       "       [0.3113 , 0.277  , 0.2483 , ..., 0.     , 1.     , 0.     ],\n",
       "       ...,\n",
       "       [0.192  , 0.318  , 0.128  , ..., 0.     , 0.     , 0.     ],\n",
       "       [0.076  , 0.1459 , 0.0797 , ..., 0.     , 1.     , 0.     ],\n",
       "       [0.3625 , 0.1692 , 0.3247 , ..., 0.     , 1.     , 0.     ]],\n",
       "      dtype=float16)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8270cd60-7d83-4eab-a5c6-5999d8aec7dd",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6856ffad-2a02-4432-947a-ce46bfae54b2",
   "metadata": {},
   "source": [
    "## Construccion del modelo \n",
    "\n",
    "El modelo a construir para este problema de clasificacion binaria consiste en una red neuronal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "61b6b681-19dc-45e1-bb02-344578e26612",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_19 (Dense)            (None, 512)               36864     \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 37,377\n",
      "Trainable params: 37,377\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Defino la arquitectura del modelo\n",
    "model = Sequential([\n",
    "    layers.Input(shape = 71),\n",
    "    layers.Dense(units = 512, activation = \"relu\"),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(units = 1, activation = \"softmax\")\n",
    "])\n",
    "\n",
    "# Compilo el modelo\n",
    "model.compile(\n",
    "    optimizer = 'sgd',\n",
    "    loss = ['binary_crossentropy'],\n",
    "    metrics = ['accuracy']\n",
    ")\n",
    "\n",
    "# Reviso la arquitectura del modelo\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "547f9eb0-a94b-4460-9c47-eef176513965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "64/64 [==============================] - 1s 7ms/step - loss: 0.6851 - accuracy: 0.5594 - val_loss: 0.6784 - val_accuracy: 0.5579\n",
      "Epoch 2/100\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.6746 - accuracy: 0.5594 - val_loss: 0.6699 - val_accuracy: 0.5579\n",
      "Epoch 3/100\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.6667 - accuracy: 0.5594 - val_loss: 0.6622 - val_accuracy: 0.5579\n",
      "Epoch 4/100\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.6593 - accuracy: 0.5594 - val_loss: 0.6551 - val_accuracy: 0.5579\n",
      "Epoch 5/100\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.6522 - accuracy: 0.5594 - val_loss: 0.6485 - val_accuracy: 0.5579\n",
      "Epoch 6/100\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.6462 - accuracy: 0.5594 - val_loss: 0.6425 - val_accuracy: 0.5579\n",
      "Epoch 7/100\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.6404 - accuracy: 0.5594 - val_loss: 0.6367 - val_accuracy: 0.5579\n",
      "Epoch 8/100\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.6352 - accuracy: 0.5594 - val_loss: 0.6314 - val_accuracy: 0.5579\n",
      "Epoch 9/100\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.6296 - accuracy: 0.5594 - val_loss: 0.6263 - val_accuracy: 0.5579\n",
      "Epoch 10/100\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.6250 - accuracy: 0.5594 - val_loss: 0.6216 - val_accuracy: 0.5579\n",
      "Epoch 11/100\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.6210 - accuracy: 0.5594 - val_loss: 0.6172 - val_accuracy: 0.5579\n",
      "Epoch 12/100\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.6166 - accuracy: 0.5594 - val_loss: 0.6129 - val_accuracy: 0.5579\n",
      "Epoch 13/100\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.6129 - accuracy: 0.5594 - val_loss: 0.6089 - val_accuracy: 0.5579\n",
      "Epoch 14/100\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.6080 - accuracy: 0.5594 - val_loss: 0.6051 - val_accuracy: 0.5579\n",
      "Epoch 15/100\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.6049 - accuracy: 0.5594 - val_loss: 0.6014 - val_accuracy: 0.5579\n",
      "Epoch 16/100\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.6017 - accuracy: 0.5594 - val_loss: 0.5979 - val_accuracy: 0.5579\n",
      "Epoch 17/100\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.5985 - accuracy: 0.5594 - val_loss: 0.5946 - val_accuracy: 0.5579\n",
      "Epoch 18/100\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.5954 - accuracy: 0.5594 - val_loss: 0.5914 - val_accuracy: 0.5579\n",
      "Epoch 19/100\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.5923 - accuracy: 0.5594 - val_loss: 0.5883 - val_accuracy: 0.5579\n",
      "Epoch 20/100\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.5889 - accuracy: 0.5594 - val_loss: 0.5853 - val_accuracy: 0.5579\n",
      "Epoch 21/100\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.5868 - accuracy: 0.5594 - val_loss: 0.5825 - val_accuracy: 0.5579\n",
      "Epoch 22/100\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.5837 - accuracy: 0.5594 - val_loss: 0.5797 - val_accuracy: 0.5579\n",
      "Epoch 23/100\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.5813 - accuracy: 0.5594 - val_loss: 0.5770 - val_accuracy: 0.5579\n",
      "Epoch 24/100\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.5789 - accuracy: 0.5594 - val_loss: 0.5744 - val_accuracy: 0.5579\n",
      "Epoch 25/100\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.5759 - accuracy: 0.5594 - val_loss: 0.5719 - val_accuracy: 0.5579\n",
      "Epoch 26/100\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.5734 - accuracy: 0.5594 - val_loss: 0.5695 - val_accuracy: 0.5579\n",
      "Epoch 27/100\n",
      "64/64 [==============================] - 0s 6ms/step - loss: 0.5715 - accuracy: 0.5594 - val_loss: 0.5671 - val_accuracy: 0.5579\n",
      "Epoch 28/100\n",
      "64/64 [==============================] - 0s 6ms/step - loss: 0.5689 - accuracy: 0.5594 - val_loss: 0.5647 - val_accuracy: 0.5579\n",
      "Epoch 29/100\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.5662 - accuracy: 0.5594 - val_loss: 0.5624 - val_accuracy: 0.5579\n",
      "Epoch 30/100\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.5643 - accuracy: 0.5594 - val_loss: 0.5602 - val_accuracy: 0.5579\n",
      "Epoch 31/100\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.5631 - accuracy: 0.5594 - val_loss: 0.5580 - val_accuracy: 0.5579\n",
      "Epoch 32/100\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.5603 - accuracy: 0.5594 - val_loss: 0.5559 - val_accuracy: 0.5579\n",
      "Epoch 33/100\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.5574 - accuracy: 0.5594 - val_loss: 0.5538 - val_accuracy: 0.5579\n",
      "Epoch 34/100\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.5560 - accuracy: 0.5594 - val_loss: 0.5518 - val_accuracy: 0.5579\n",
      "Epoch 35/100\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.5546 - accuracy: 0.5594 - val_loss: 0.5498 - val_accuracy: 0.5579\n",
      "Epoch 36/100\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.5526 - accuracy: 0.5594 - val_loss: 0.5479 - val_accuracy: 0.5579\n",
      "Epoch 37/100\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.5503 - accuracy: 0.5594 - val_loss: 0.5459 - val_accuracy: 0.5579\n",
      "Epoch 38/100\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.5481 - accuracy: 0.5594 - val_loss: 0.5440 - val_accuracy: 0.5579\n",
      "Epoch 39/100\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.5465 - accuracy: 0.5594 - val_loss: 0.5421 - val_accuracy: 0.5579\n",
      "Epoch 40/100\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.5454 - accuracy: 0.5594 - val_loss: 0.5402 - val_accuracy: 0.5579\n",
      "Epoch 41/100\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.5430 - accuracy: 0.5594 - val_loss: 0.5385 - val_accuracy: 0.5579\n",
      "Epoch 42/100\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.5410 - accuracy: 0.5594 - val_loss: 0.5366 - val_accuracy: 0.5579\n",
      "Epoch 43/100\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.5399 - accuracy: 0.5594 - val_loss: 0.5348 - val_accuracy: 0.5579\n",
      "Epoch 44/100\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.5373 - accuracy: 0.5594 - val_loss: 0.5330 - val_accuracy: 0.5579\n",
      "Epoch 45/100\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.5356 - accuracy: 0.5594 - val_loss: 0.5313 - val_accuracy: 0.5579\n",
      "Epoch 46/100\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.5339 - accuracy: 0.5594 - val_loss: 0.5295 - val_accuracy: 0.5579\n",
      "Epoch 47/100\n",
      "64/64 [==============================] - 0s 6ms/step - loss: 0.5320 - accuracy: 0.5594 - val_loss: 0.5278 - val_accuracy: 0.5579\n",
      "Epoch 48/100\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.5302 - accuracy: 0.5594 - val_loss: 0.5260 - val_accuracy: 0.5579\n",
      "Epoch 49/100\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.5291 - accuracy: 0.5594 - val_loss: 0.5243 - val_accuracy: 0.5579\n",
      "Epoch 50/100\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.5270 - accuracy: 0.5594 - val_loss: 0.5226 - val_accuracy: 0.5579\n",
      "Epoch 51/100\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.5253 - accuracy: 0.5594 - val_loss: 0.5209 - val_accuracy: 0.5579\n",
      "Epoch 52/100\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.5235 - accuracy: 0.5594 - val_loss: 0.5193 - val_accuracy: 0.5579\n",
      "Epoch 53/100\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.5214 - accuracy: 0.5594 - val_loss: 0.5176 - val_accuracy: 0.5579\n",
      "Epoch 54/100\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.5213 - accuracy: 0.5594 - val_loss: 0.5159 - val_accuracy: 0.5579\n",
      "Epoch 55/100\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.5190 - accuracy: 0.5594 - val_loss: 0.5143 - val_accuracy: 0.5579\n",
      "Epoch 56/100\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.5176 - accuracy: 0.5594 - val_loss: 0.5127 - val_accuracy: 0.5579\n",
      "Epoch 57/100\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.5155 - accuracy: 0.5594 - val_loss: 0.5110 - val_accuracy: 0.5579\n",
      "Epoch 58/100\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.5141 - accuracy: 0.5594 - val_loss: 0.5095 - val_accuracy: 0.5579\n",
      "Epoch 59/100\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.5119 - accuracy: 0.5594 - val_loss: 0.5078 - val_accuracy: 0.5579\n",
      "Epoch 60/100\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.5104 - accuracy: 0.5594 - val_loss: 0.5062 - val_accuracy: 0.5579\n",
      "Epoch 61/100\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.5094 - accuracy: 0.5594 - val_loss: 0.5046 - val_accuracy: 0.5579\n",
      "Epoch 62/100\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.5074 - accuracy: 0.5594 - val_loss: 0.5030 - val_accuracy: 0.5579\n",
      "Epoch 63/100\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.5050 - accuracy: 0.5594 - val_loss: 0.5014 - val_accuracy: 0.5579\n",
      "Epoch 64/100\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.5048 - accuracy: 0.5594 - val_loss: 0.4998 - val_accuracy: 0.5579\n",
      "Epoch 65/100\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.5023 - accuracy: 0.5594 - val_loss: 0.4982 - val_accuracy: 0.5579\n",
      "Epoch 66/100\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.5009 - accuracy: 0.5594 - val_loss: 0.4966 - val_accuracy: 0.5579\n",
      "Epoch 67/100\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.4986 - accuracy: 0.5594 - val_loss: 0.4950 - val_accuracy: 0.5579\n",
      "Epoch 68/100\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.4976 - accuracy: 0.5594 - val_loss: 0.4934 - val_accuracy: 0.5579\n",
      "Epoch 69/100\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.4963 - accuracy: 0.5594 - val_loss: 0.4919 - val_accuracy: 0.5579\n",
      "Epoch 70/100\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.4946 - accuracy: 0.5594 - val_loss: 0.4902 - val_accuracy: 0.5579\n",
      "Epoch 71/100\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.4924 - accuracy: 0.5594 - val_loss: 0.4887 - val_accuracy: 0.5579\n",
      "Epoch 72/100\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.4917 - accuracy: 0.5594 - val_loss: 0.4871 - val_accuracy: 0.5579\n",
      "Epoch 73/100\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.4901 - accuracy: 0.5594 - val_loss: 0.4855 - val_accuracy: 0.5579\n",
      "Epoch 74/100\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.4873 - accuracy: 0.5594 - val_loss: 0.4839 - val_accuracy: 0.5579\n",
      "Epoch 75/100\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.4867 - accuracy: 0.5594 - val_loss: 0.4823 - val_accuracy: 0.5579\n",
      "Epoch 76/100\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.5594 - val_loss: 0.4808 - val_accuracy: 0.5579\n",
      "Epoch 77/100\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.4838 - accuracy: 0.5594 - val_loss: 0.4791 - val_accuracy: 0.5579\n",
      "Epoch 78/100\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.4806 - accuracy: 0.5594 - val_loss: 0.4775 - val_accuracy: 0.5579\n",
      "Epoch 79/100\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.4797 - accuracy: 0.5594 - val_loss: 0.4759 - val_accuracy: 0.5579\n",
      "Epoch 80/100\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.4780 - accuracy: 0.5594 - val_loss: 0.4743 - val_accuracy: 0.5579\n",
      "Epoch 81/100\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.4770 - accuracy: 0.5594 - val_loss: 0.4727 - val_accuracy: 0.5579\n",
      "Epoch 82/100\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.4755 - accuracy: 0.5594 - val_loss: 0.4711 - val_accuracy: 0.5579\n",
      "Epoch 83/100\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.4735 - accuracy: 0.5594 - val_loss: 0.4695 - val_accuracy: 0.5579\n",
      "Epoch 84/100\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.4716 - accuracy: 0.5594 - val_loss: 0.4679 - val_accuracy: 0.5579\n",
      "Epoch 85/100\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.4701 - accuracy: 0.5594 - val_loss: 0.4664 - val_accuracy: 0.5579\n",
      "Epoch 86/100\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.4692 - accuracy: 0.5594 - val_loss: 0.4648 - val_accuracy: 0.5579\n",
      "Epoch 87/100\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.5594 - val_loss: 0.4632 - val_accuracy: 0.5579\n",
      "Epoch 88/100\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.4653 - accuracy: 0.5594 - val_loss: 0.4617 - val_accuracy: 0.5579\n",
      "Epoch 89/100\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.4645 - accuracy: 0.5594 - val_loss: 0.4601 - val_accuracy: 0.5579\n",
      "Epoch 90/100\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.4626 - accuracy: 0.5594 - val_loss: 0.4585 - val_accuracy: 0.5579\n",
      "Epoch 91/100\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.4606 - accuracy: 0.5594 - val_loss: 0.4569 - val_accuracy: 0.5579\n",
      "Epoch 92/100\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.4590 - accuracy: 0.5594 - val_loss: 0.4554 - val_accuracy: 0.5579\n",
      "Epoch 93/100\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.4576 - accuracy: 0.5594 - val_loss: 0.4538 - val_accuracy: 0.5579\n",
      "Epoch 94/100\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.4562 - accuracy: 0.5594 - val_loss: 0.4523 - val_accuracy: 0.5579\n",
      "Epoch 95/100\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.4547 - accuracy: 0.5594 - val_loss: 0.4508 - val_accuracy: 0.5579\n",
      "Epoch 96/100\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.4538 - accuracy: 0.5594 - val_loss: 0.4491 - val_accuracy: 0.5579\n",
      "Epoch 97/100\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.4518 - accuracy: 0.5594 - val_loss: 0.4476 - val_accuracy: 0.5579\n",
      "Epoch 98/100\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.4499 - accuracy: 0.5594 - val_loss: 0.4461 - val_accuracy: 0.5579\n",
      "Epoch 99/100\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.4481 - accuracy: 0.5594 - val_loss: 0.4444 - val_accuracy: 0.5579\n",
      "Epoch 100/100\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.4464 - accuracy: 0.5594 - val_loss: 0.4429 - val_accuracy: 0.5579\n"
     ]
    }
   ],
   "source": [
    "# Entreno el modelo con el conjunto de entrenamiento\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=100,\n",
    "    validation_split=0.15,\n",
    "    steps_per_epoch=64\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c0103a-6d64-4d25-817c-5a7cc3c867ca",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e134fa-a4a8-4dd8-933a-46cbe6f21e8c",
   "metadata": {},
   "source": [
    "### Evaluo el modelo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907cfd65-5f18-483b-b53d-433f43de6e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genero predicciones para el conjunto de prueba\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = [0 if _ <= 0.5 else 1 for _ in y_pred]\n",
    "\n",
    "# Genero una matriz de confusion para evaluar el rendimiento del modelo entrenado\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(conf_matrix)\n",
    "print(class_report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
